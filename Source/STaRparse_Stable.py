#!/usr/bin/env python3
""" "@author: dannear """

import sys, argparse, glob, datetime, sqlalchemy, random, subprocess

class STaRparse(object):

    def __init__(self):
        parser = argparse.ArgumentParser(
            description='Tool for managing data generated by STR genotyping tools',
            usage='''STaRparse <command> [<args>]

The avaialble commands are:
    vcfparse         Collects relevant data from VCF files.
    csvmerge         Merges CSV tables generated by vcfparse.
    summaries        Summarizes data generated by vcfparse.
    repeatpanel      Generate BED and JSON files for GangSTR and ExpansionHunter respectively.
''')
        parser.add_argument('command', help='Subcommand to run')
        args = parser.parse_args(sys.argv[1:2])
        if not hasattr(self, args.command):
            print('Unrecognized command')
            parser.print_help()
            exit(1)
        getattr(self, args.command)()

    def vcfparse(self):
        sys.path.insert(1, "/home/dannear/STaRparse/bin/Source/Scripts/vcfparse")
        parser = argparse.ArgumentParser(description='Select VCF directory and STR genotyper.')
        parser.add_argument('STR_Genotyper', choices=['E','G','L'], metavar="", help='E (ExpansionHunter), G (GangSTR), or L (lobSTR))')
        parser.add_argument('-i', '--vcfinput', type=str, metavar="", required=True, help='VCF Input File Path')
        parser.add_argument('-o', '--output', type=str, metavar="", nargs="?", const="/home/dannear/STaRparse/Default_Output", required=False, help='CSV Output File Path')
        parser.add_argument('-db', '--database', type=str, metavar="", required=False, help='Enter Database Name')
        args = parser.parse_args(sys.argv[2:])

        #           DEFINE VCF_to_CSV_to_DB SCRIPT
        def to_DB(df, dbname, out_code):
        #           EXPORT TO DATABASE AND CSV
            print("###############     EXPORTING TO DATABASE    ###############")
            engine = sqlalchemy.create_engine("mysql+pymysql://dannear:3vVrnhJ3@143.169.238.18/dannear")
            df.to_sql("CGG_Repeats_"+dbname+"_"+out_code, engine, if_exists='replace', index=False)

        def Output(vcf_data, out_code, output, db):
            vcf_data.to_csv(output+"CGG_Repeats_"+db+"_"+out_code+".csv", sep=',', index=None, header=True)
            if db != "":
                to_DB(vcf_data, db, out_code)
            else:
                print("WARNING: \t VCF data will not be exported to a database. No database was specified.")
            print("###############     COMPLETE     ###############")
            print("Output CSV file can be found at: "+output+"CGG_Repeats_"+db+"_"+out_code+".csv")

        if args.output[-1] != "/":
            args.output += "/"
        if args.vcfinput[-1] != "/":
            args.vcfinput += "/"
        out_code = "".join([str(datetime.datetime.today().strftime('%Y-%m-%d')), "_", str(random.randint(1,10000))])
        files = glob.glob(args.vcfinput+'*.vcf')

        if files == []:
            print("WARNING: \t No VCF files were found at the specified directory.")
            exit(1)
        else:
            print(files)
            if args.database is None:
                db = ""
            else:
                db = args.database

        if args.STR_Genotyper == "E":
            out_code = "ExpansionHunter_" + out_code
            from From_ExpansionHunter import ExpansionHunter
            vcf_data = ExpansionHunter(files, out_code)
        if args.STR_Genotyper == "G":
            out_code = "GangSTR_" + out_code
            from From_GangSTR import GangSTR
            vcf_data = GangSTR(files, out_code)
        Output(vcf_data, out_code, args.output, db)

    def csvmerge(self):
        sys.path.insert(1, "/home/dannear/STaRparse/bin/Source/Scripts/csvmerge")
        parser = argparse.ArgumentParser(description='Merge CSV files containnig ExpansionHunter and GangSTR data')
        parser.add_argument('-e', '--expansionhuntercsv', type=str, metavar="", required=True, help='ExpansionHunter CSV file path')
        parser.add_argument('-g', '--gangstrcsv', type=str, metavar="", required=True, help='GangSTR CSV file path')
        parser.add_argument('-o', '--outputcsv', type=str, metavar="", required=True, help='Output CSV file path')
        args = parser.parse_args(sys.argv[2:])

        path2script1 = '/home/dannear/STaRparse/bin/Source/Scripts/csvmerge/CSV_Merge_Consensus.R'
        arguments = [args.expansionhuntercsv, args.gangstrcsv, args.outputcsv]
        cmd = ['Rscript', path2script1] + arguments
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        p.stdout.read()

        print("Output CSV files can be found at: " + args.outputcsv + "_merged.csv & " + args.outputcsv + "_consensus.csv")

        print("###############     COMPLETE     ###############")

    def summaries(self):
        sys.path.insert(1, "/home/dannear/STaRparse/bin/Source/Scripts/summaries")
        parser = argparse.ArgumentParser(description='Summarise data stored in CSV Files')
        parser.add_argument('-i', '--csvinput', type=str, metavar="", required=True, help='Input CSV file path')
        parser.add_argument('-o', '--summaryoutput', type=str, metavar="", required=True, help='Summary output file path')
        args = parser.parse_args(sys.argv[2:])

        path2script = '/home/dannear/STaRparse/bin/Source/Scripts/summaries/Summaries.R'
        arguments = [args.csvinput, args.summaryoutput]
        cmd = ['Rscript', path2script] + arguments
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        p.stdout.read()

        print("Summary File Written, Sample        : " + args.summaryoutput + "_by_Sample.csv")
        print("Summary File Written, Chromosome    : " + args.summaryoutput + "_by_Chr.csv")
        print("Summary File Written, Locus         : " + args.summaryoutput + "_by_Locus.csv")
        print("Summary File Written, Stability     : " + args.summaryoutput + "_by_Stability.csv")
        print("###############     COMPLETE     ###############")

    def repeatpanel(self):
        sys.path.insert(1, "/home/dannear/STaRparse/bin/Source/Scripts/repeatpanel")
        parser = argparse.ArgumentParser(description='Generate BED and JSON files for STR genotypes from an original TRF Input')
        parser.add_argument('-i', '--input', type=str, metavar="", nargs="?", const="/home/dannear/STaRparse/bin/Source/Scripts/repeatpanel/TRF_CGG_Repeat_Panel.bed", required=True, help='TRF Input BED File')
        parser.add_argument('-o', '--output', type=str, metavar="", nargs="?", required=True, help='BED and JSON file output directory')
        parser.add_argument('-m', '--match', type=str, metavar="", required=False, help='Local alignment parameter: Nucleotide Match')
        parser.add_argument('-n', '--nonmatch', type=str, metavar="", required=False, help='Local alignment parameter: Nucleotide non-Match')
        parser.add_argument('-g', '--gap', type=str, metavar="", required=False, help='Local alignment parameter: Open Gap')
        parser.add_argument('-e', '--extendgap', type=str, metavar="", required=False, help='Local alignment parameter: Extend Gap')
        args = parser.parse_args(sys.argv[2:])

        from TRF_Filter import construct

        if args.output[len(args.output)-1] != "/":
            outpath = args.output+"/"
        else:
            outpath = args.output

        alignment_paramters = [args.match, args.nonmatch, args.gap, args.extendgap]
        for x in alignment_paramters:
            if not x:
                alignment_paramters = [1/2, -2, -5, -1]

        names = ["Chr", "Start", "End", "Pattern_Size", "Units", "Copies_Aligned", "Match%", "Indels%", "Alignment_Score", "A%", "C%", "G%", "T%", "Entropy", "Pattern", "Motif"]
        content = {"Chr":[], "Start":[], "End":[], "Pattern_Size":[], "Units":[], "Copies_Aligned":[], "Match%":[], "Indels%":[], "Alignment_Score":[], "A%":[], "C%":[], "G%":[], "T%":[], "Entropy":[], "Pattern":[], "Motif":[]}

        with open(args.input) as f:
            for line in f:
                for x in range(len(names)):
                    content[names[x]].append(line.strip().split()[x])

        repeatdf = construct(content, names, alignment_paramters)
        out_code = "".join([str(datetime.datetime.today().strftime('%Y-%m-%d')), "_", str(random.randint(1,10000))])

        outfile = outpath + "TRF_Panel_Filtered_" + out_code + ".bed"

        repeatdf.to_csv(outfile, index = None, header=False, sep="\t")
        print("File written:   ", outfile)

        path2script = '/home/dannear/STaRparse/bin/Source/Scripts/repeatpanel/TRF_Construct.R'
        arguments = [outpath, outfile, out_code]
        cmd = ['Rscript', path2script] + arguments
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        p.stdout.read()

        print("File Written:   ", outpath + "TRF_Panel_GangSTR_" + out_code + ".bed")
        print("File Written:   ", outpath + "TRF_Panel_ExpansionHunter_" + out_code + ".json")
        print("###############     COMPLETE     ###############")

if __name__ == '__main__':
    STaRparse()